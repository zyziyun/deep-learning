## 3层神经网络的实现
- 重点是神经网络的运算可以作为矩阵运算打包进行
- 神经网络各层的运算是通过矩阵的乘法运算打包进行的（从宏观视角来考虑）
- 输入层 -> 隐藏层（1、2）-> 输出层
    - 使用激活函数（sigmoid）层层叠加
- 输出层所用的激活函数，要根据求解问题的性质决定。一般地，回归问题可以使用恒等函数，二元分类问题可以使用sigmoid函数，多元分类问题可以使用softmax函数。

## 输出层设计
- 神经网络可以用在分类问题和回归问题上
- 回归问题用恒等函数，分类问题用 softmax 函数
    - 恒等函数（输入信号会原封不动地被输出）
    - softmax函数
* 机器学习的问题大致可以分为分类问题和回归问题
    - 分类问题是数据属于哪一个类别的问题（区分图像中的人是男性还是女性）
    - 回归问题是根据某个输入预测一个（连续的）数值的问题（根据一个人的图像预测这个人的体重的问题）
    
* softmax函数
![avatar](./softmax_expression.jpeg)
- softmax函数的输出是0.0到1.0之间的实数
- softmax函数的输出值的总和是1，输出总和为 1 是 softmax 函数的一个重要性质。
- 正因为有了这个性质，我们才可以把 softmax 函数的输出解释为“概率”。
- 即便使用了 softmax 函数，各个元素之间的大小关系也不会改变
- 函数（y = exp(x)）是单调递增函数
- 例中 a 的各元素的大小关系和 y 的各元素的大小关系并没有改变。
- 神经网络只把输出值最大的神经元所对应的类别作为识别结果，即便使用 softmax 函数，输出值最大的神经元的位置也不会变

## 手写数字识别