## 其他参数的调优

### 过拟合问题
* `过拟合`
- 只能拟合训练数据，不能很好地拟合不包含在训练数据中的其他数据
- 原因: 1) 模型拥有大量参数、表现力强 2) 训练数据少

* 解决方法

#### 权值衰减
- 通过在学习的过程中对大的权重进行惩罚，来抑制过拟合
- 神经网络的学习目的是减小损失函数的值，例如为损失函数加上权重的平方范数（L2 范数）。这样一来，就可以抑制权重变大。
- 权重W加上L2 范数（相当于各个元素的平方和，除了 L2 范数，还有 L1 范数、L ∞范数等）

#### Dropout
- 为损失函数加上权重的 L2 范数的权值衰减方法。该方法可以简单地实现，在某种程度上能够抑制过拟合。
- 如果网络的模型变得很复杂，只用权值衰减就难以应对了。在这种情况下，我们经常会使用 Dropout 方法。
- Dropout: 是一种在学习的过程中随机删除神经元的方法
- 过程：训练时，随机选出隐藏层的神经元，然后将其删除。被删除的神经元不再进行信号的传递，但是测试时，虽然会传递所有的神经元信号，但是对于各个神经元的输出，要乘上训练时的删除比例后再输出。
- 即便是表现力强的网络，也可以抑制过拟合。

#### 集成学习
- 让多个模型单独进行学习，推理时再取多个模型的输出的平均值（通过进行集成学习，神经网络的识别精度可以提高好几个百分点）
- Dropout 理解为，通过在学习过程中随机删除神经元，从而每一次都让不同的模型进行学习。
- 推理时，通过对神经元的输出乘以删除比例（比如，0.5 等），可以取得模型的平均值。
- Dropout将集成学习的效果（模拟地）通过一个网络实现了。

### 超参数的验证
- 超参数（hyper-parameter）：指各层的神经元数量、batch 大小、参数更新时的学习率或权值衰减等
- 对超参数的验证，不能使用测试数据评估超参数的性能（因为超参数的值会对测试数据发生过拟合）
- 调整超参数时，必须使用超参数专用的确认数据。用于调整超参数的数据，一般称为验证数据（validation data）。使用这个验证数据来评估超参数的好坏。

#### 三种数据源
- 训练数据用于参数（权重和偏置）的学习
- 验证数据用于超参数的性能评估。
- 为了确认泛化能力，要在最后使用（比较理想的是只用一次）测试数据。

#### 超参数的最优化
- 逐渐缩小超参数的“好值”的存在范围：先大致设定一个范围，从这个范围中随机选出一个超参数（采样），用这个采样到的值进行识别精度的评估；多次重复该操作，观察识别精度的结果，根据这个结果缩小超参数的“好值”的范围。通过重复这一操作，就可以逐渐确定超参数的合适范围。
- 内容：
    1. 设定超参数的范围。
    2. 从设定的超参数范围中随机采样。
    3. 使用步骤 1 中采样到的超参数的值进行学习，通过验证数据评估识别精度（但是要将 epoch 设置得很小）。
    4. 重复步骤 1 和步骤 2（100 次等），根据它们的识别精度的结果，缩小超参数的范围。
- 如果需要更精炼的方法，可以使用贝叶斯最优化（Bayesian optimization）（以贝叶斯定理为中心的数学理论、更严密高效）



